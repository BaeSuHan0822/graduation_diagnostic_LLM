import os,shutil
from langchain_text_splitters import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings

embedding_function = HuggingFaceEmbeddings(
    model_name = "intfloat/multilingual-e5-small",
    model_kwargs = {"device" : "cpu"},
    encode_kwargs = {"normalize_embeddings" : True}
)

PATH = os.path.dirname(__file__)
file_path = os.path.join(PATH,"curriculum_db")
computer_file_path = os.path.join(file_path,"computer_science")
humanitas_file_path = os.path.join(file_path,"humanitas")

if os.path.exists(os.path.join(PATH,"chroma_db")) :
    print("â€¼ï¸ ë²¡í„° DBê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ì‚­ì œí•˜ê³  ì—…ë°ì´íŠ¸í• ê¹Œìš” ? â€¼ï¸")
    if input("[Y/N]").lower() == "n" :
        print("âœ… ì¢…ë£Œí•©ë‹ˆë‹¤.")
        exit()
    print("âœ… DBë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤ !")
    shutil.rmtree(os.path.join(PATH,"chroma_db"))
    
header_splitters = [
    ("#", "header_1"),
    ("##", "header_2"),
    ("###", "header_3"),
]

markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=header_splitters)
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=800,
    chunk_overlap=100
)

def process_folder(folder_path, category_name):
    documents = []
    
    if not os.path.exists(folder_path):
        print(f"âš ï¸ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {folder_path}")
        return documents

    files = os.listdir(folder_path)
    print(f"ğŸ“‚ {category_name} í´ë” ì²˜ë¦¬ ì‹œì‘ ({len(files)}ê°œ íŒŒì¼)")

    for file in files:
        if file.endswith(".txt") or not file.endswith(".md"): # .md íŒŒì¼ë§Œ ì²˜ë¦¬
            continue
            
        path = os.path.join(folder_path, file)
        
        # 1) íŒŒì¼ ì½ê¸°
        with open(path, "r", encoding="utf-8") as f:
            raw_text = f.read()
        
        # 2) í—¤ë” ê¸°ì¤€ 1ì°¨ ë¶„í• 
        header_splits = markdown_splitter.split_text(raw_text)
        
        # 3) ë‚´ìš© ê¸¸ì´ ê¸°ì¤€ 2ì°¨ ë¶„í•  ë° ë©”íƒ€ë°ì´í„° ì£¼ì…
        for split in header_splits:
            if len(split.page_content) > 1000:
                final_splits = text_splitter.split_documents([split])
            else:
                final_splits = [split]
                
            # âœ… [ìˆ˜ì •ë¨] ë“¤ì—¬ì“°ê¸°ë¥¼ ì•ˆìª½ìœ¼ë¡œ ë„£ì–´ì„œ ëª¨ë“  splitì„ ì²˜ë¦¬í•˜ê²Œ í•¨
            for doc in final_splits:
                doc.page_content = f"passage: {doc.page_content}"
                doc.metadata["source"] = file
                doc.metadata["category"] = category_name
                documents.append(doc)
                
    print(f"   -> {len(documents)}ê°œì˜ ì²­í¬ ìƒì„± ì™„ë£Œ")
    return documents


computer_documents = process_folder(computer_file_path,"computer_science")
humanitas_documents = process_folder(humanitas_file_path,"humanitas")

computer_db = Chroma.from_documents(
    documents = computer_documents,
    embedding = embedding_function,
    persist_directory = os.path.join(PATH,"chroma_db"),
    collection_name = "computer_science",
    collection_metadata = {"hnsw:space" : "cosine"}
)

humanitas_db = Chroma.from_documents(
    documents = humanitas_documents,
    embedding = embedding_function,
    persist_directory = os.path.join(PATH,"chroma_db"),
    collection_name = "humanitas",
    collection_metadata = {"hnsw:space" : "cosine"}
)